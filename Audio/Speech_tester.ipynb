{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a53a29e0-3845-43ba-ac9d-b91a2bb41f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyaudio\n",
    "import wave\n",
    "import librosa\n",
    "from scipy.io.wavfile import write\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66949a30-61a1-4e40-b025-5d263b4470ce",
   "metadata": {},
   "source": [
    "### Define function to record audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749edbe0-1f2d-42bd-a026-9a25f663228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for audio recording\n",
    "format = pyaudio.paInt16\n",
    "channels = 1\n",
    "filename = \"test/output.wav\"\n",
    "duration=5\n",
    "sample_rate=44100\n",
    "chunk_size=1024\n",
    "duration=5\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=format, channels=channels,\n",
    "                        rate=sample_rate, input=True,\n",
    "                        frames_per_buffer=chunk_size)\n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "\n",
    "    # Calculate total number of chunks\n",
    "    total_chunks = int(sample_rate / chunk_size * duration)\n",
    "    chunks_per_marker = total_chunks // 10  # Number of chunks for each '#' character\n",
    "    \n",
    "    for i in range(total_chunks):\n",
    "        data = stream.read(chunk_size)\n",
    "        frames.append(data)\n",
    "        percentage = int((i + 1) / total_chunks * 100)\n",
    "        if (i + 1) % chunks_per_marker == 0:\n",
    "            print(f\" -- {percentage}%\", end='', flush=True)  # Print '#' without newline and flush buffer\n",
    "    \n",
    "    print(\"\\nFinished recording.\")\n",
    "    \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    \n",
    "    wavefile = wave.open(filename, 'wb')\n",
    "    wavefile.setnchannels(channels)\n",
    "    wavefile.setsampwidth(audio.get_sample_size(format))\n",
    "    wavefile.setframerate(sample_rate)\n",
    "    wavefile.writeframes(b''.join(frames))\n",
    "    wavefile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e7005-86d6-4267-810a-3e0eced48ed4",
   "metadata": {},
   "source": [
    "### Define function to preprocess audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fdba425-52e5-4125-bc60-8957efa9e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample feature\n",
    "#librosa.core.load(path, sr=22050, mono=True, offset=0.0, duration=None, dtype=<class 'numpy.float32'>, res_type='kaiser_best')\n",
    "\n",
    "#Mfcc\n",
    "#librosa.feature.mfcc(y=None, sr=22050, S=None, n_mfcc=20, dct_type=2, norm='ortho', lifter=0, **kwargs)\n",
    "mfcc_sample_rate = 22050\n",
    "n_mfcc = 40\n",
    "axis_mfcc = 1\n",
    "\n",
    "# Function to preprocess audio\n",
    "\n",
    "def preprocess_audio(filename, sample_rate=22050, n_mfcc=40,offset_s = 0.5):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(filename, sr=sample_rate, mono=True,offset=offset_s)\n",
    "    \n",
    "    # Extract MFCC features\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    \n",
    "    # Calculate mean of MFCCs\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    \n",
    "    return mfccs_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6a3ea-8a4f-4d9f-970e-d4975b335b0e",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad07588-7b5f-4b6d-8c74-718c1fde46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "def load_model(model_json_path, model_weights_path):\n",
    "    json_file = open(model_json_path, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(model_weights_path)\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f0b5d0-dfae-4f4c-b5a2-be1833a3e26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ee389bd-0b97-46c3-8c7c-1e37f5b68cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "model_json_path = 'models/train_fit/final_model.json'\n",
    "model_weights_path = 'models/train_fit/final_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a10c84a-f3db-4b58-afa3-e220f5677b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record audio\n",
    "#record_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a8c6171-827c-4920-9e1c-bbf1b3506379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess audio\n",
    "filename = \"test/sad.wav\"\n",
    "processed_audio = preprocess_audio(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "641dfd48-fd0d-4289-aa33-db88dbd5426d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffb5276-7137-4758-84e1-53009e586db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be5bf476-501f-4592-8f85-179bc320ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "au = np.expand_dims(processed_audio, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5ea9e-e849-4de4-9b60-289244ed0ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c838abd-625f-48ac-9a0a-13592a540c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f6bcc892-9e56-40ca-bba9-ce95a5bc7daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['feature'])\n",
    "df.loc[0] = [processed_audio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9170ad8-2c7f-4da5-ad05-5295e1614112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-687.9938, 83.8148, 1.5396544, 13.143715, 8.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature\n",
       "0  [-687.9938, 83.8148, 1.5396544, 13.143715, 8.0..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "80fbe602-05fc-4d96-9814-a80846bf258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn array into dataframe\n",
    "df = pd.DataFrame(df['feature'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2b236df1-f67c-4100-a222-e275b590522c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-687.993774</td>\n",
       "      <td>83.814796</td>\n",
       "      <td>1.539654</td>\n",
       "      <td>13.143715</td>\n",
       "      <td>8.098424</td>\n",
       "      <td>-2.608693</td>\n",
       "      <td>-5.921618</td>\n",
       "      <td>-12.662955</td>\n",
       "      <td>-7.82617</td>\n",
       "      <td>-2.332629</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.221829</td>\n",
       "      <td>-1.125348</td>\n",
       "      <td>-0.966688</td>\n",
       "      <td>-0.903053</td>\n",
       "      <td>-1.418783</td>\n",
       "      <td>-1.934486</td>\n",
       "      <td>-4.277811</td>\n",
       "      <td>-0.757094</td>\n",
       "      <td>-1.361607</td>\n",
       "      <td>3.472135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1         2          3         4         5         6   \\\n",
       "0 -687.993774  83.814796  1.539654  13.143715  8.098424 -2.608693 -5.921618   \n",
       "\n",
       "          7        8         9   ...        30        31        32        33  \\\n",
       "0 -12.662955 -7.82617 -2.332629  ... -4.221829 -1.125348 -0.966688 -0.903053   \n",
       "\n",
       "         34        35        36        37        38        39  \n",
       "0 -1.418783 -1.934486 -4.277811 -0.757094 -1.361607  3.472135  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1958ee91-7497-4324-9271-195addbbe3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca16755f-e633-4d6b-b7af-4cca43e7b410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = load_model(model_json_path, model_weights_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cd47c0e-e310-4a0f-8f6a-e47c665d09b4",
   "metadata": {},
   "source": [
    "# Reshape audio for CNN input\n",
    "processed_audio_reshaped = np.expand_dims(input_audio, axis=2)\n",
    "\n",
    "# Scale audio manually (optional, depending on model requirements)\n",
    "# For example, if the model expects inputs to be in the range [-1, 1]:\n",
    "#processed_audio_scaled = processed_audio_reshaped / np.max(np.abs(processed_audio_reshaped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "226a378c-9574-481a-91ec-d2501853f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('meta/scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7d2dcaa4-155f-4968-9f3a-d231cc72070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cnn = scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b54e51e-121b-4cd4-bcfd-9ce06a8b220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.expand_dims(x_cnn, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665ed5f8-0943-45b3-bf7b-637b61c9c502",
   "metadata": {},
   "source": [
    "#Add dimension for CNN\n",
    "x_testcnn = np.expand_dims(input_audio, axis=2)\n",
    "\n",
    "#Check shapes of dataframes\n",
    "print(x_testcnn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b959e92e-0836-453a-b875-3e9100967852",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#Normalize the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_testcnn)\n",
    "x_cnn = scaler.transform(x_testcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "658588a2-8181-407d-86ca-20fc223e8490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict emotion using the model\n",
    "predictions = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "91e6ce01-e037-4f92-bcec-82641ba9381e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion: Angry\n"
     ]
    }
   ],
   "source": [
    "emotions = {0:'neutral', 1:'calm', 2:'happy', 3:'sad', 4:'angry', 5:'fear', 6:'disgust', 7:'surprised'}\n",
    "predicted_emotion = emotions[np.argmax(predictions)].title()\n",
    "\n",
    "print(\"Predicted Emotion:\", predicted_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c5dca2d-f1ab-4305-ba90-24c34fbcf480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f37175b-7503-4f6f-bd6d-2126d11e276b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 40, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 40, 32)            2592      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 10, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 10, 64)            10304     \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 10, 128)           41088     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               163968    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 226,824\n",
      "Trainable params: 226,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbb356d-600d-49f5-8f8b-2ccc40f1536a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text39",
   "language": "python",
   "name": "text39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
