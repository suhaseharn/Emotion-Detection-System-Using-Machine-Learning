{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84bf666-b12e-44ee-b7fb-0c4b302ac30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67246128-c429-4ea1-bb1b-58f988e16ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = []\n",
    "\n",
    "for subdir, dirs, files in os.walk('data/RawData/Ravdess'):\n",
    "    for file in files:\n",
    "        try:\n",
    "            X, sample_rate = librosa.load(os.path.join(subdir,file),\n",
    "                                         res_type='kaiser_fast')\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y = X, sr = sample_rate,\n",
    "                                                n_mfcc = 40).T, axis=0)\n",
    "            file_class = int(file[7:8]) - 1\n",
    "            arr = mfccs, file_class\n",
    "            wav.append(arr)\n",
    "        except ValueError as err:\n",
    "            print(err)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2169b5ea-5028-4c46-b444-d9cf4e12a9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2452, 40) (2452,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['new/meta\\\\y.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = zip(*wav)\n",
    "X, y = np.asarray(X), np.asarray(y)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "if not os.path.isdir('new/meta'):\n",
    "    os.makedirs('new/meta')\n",
    "joblib.dump(X, os.path.join('new/meta', 'X.joblib'))\n",
    "joblib.dump(y, os.path.join('new/meta', 'y.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35bf12f2-03ff-44b0-bb08-db4d51b08195",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c69f9832-8904-4143-a013-c006390c737f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-700.398926</td>\n",
       "      <td>58.630211</td>\n",
       "      <td>-3.025852</td>\n",
       "      <td>16.040241</td>\n",
       "      <td>4.248529</td>\n",
       "      <td>3.869935</td>\n",
       "      <td>-6.381716</td>\n",
       "      <td>-0.188635</td>\n",
       "      <td>-13.735004</td>\n",
       "      <td>-0.319724</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.411359</td>\n",
       "      <td>-2.769772</td>\n",
       "      <td>-2.042009</td>\n",
       "      <td>-2.522663</td>\n",
       "      <td>-2.507448</td>\n",
       "      <td>-2.250499</td>\n",
       "      <td>-0.381506</td>\n",
       "      <td>-2.481059</td>\n",
       "      <td>-2.791022</td>\n",
       "      <td>-2.244865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-653.169006</td>\n",
       "      <td>58.028076</td>\n",
       "      <td>-12.581207</td>\n",
       "      <td>11.818786</td>\n",
       "      <td>-7.681562</td>\n",
       "      <td>-0.617142</td>\n",
       "      <td>-8.337758</td>\n",
       "      <td>-5.823570</td>\n",
       "      <td>-6.547592</td>\n",
       "      <td>1.458057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788761</td>\n",
       "      <td>2.570493</td>\n",
       "      <td>2.558634</td>\n",
       "      <td>3.708506</td>\n",
       "      <td>2.790020</td>\n",
       "      <td>2.201920</td>\n",
       "      <td>-1.021456</td>\n",
       "      <td>0.819200</td>\n",
       "      <td>-0.277811</td>\n",
       "      <td>0.207586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-617.052307</td>\n",
       "      <td>60.103371</td>\n",
       "      <td>-5.984258</td>\n",
       "      <td>13.886285</td>\n",
       "      <td>1.120427</td>\n",
       "      <td>0.511750</td>\n",
       "      <td>-14.841356</td>\n",
       "      <td>-4.016369</td>\n",
       "      <td>-5.575839</td>\n",
       "      <td>-6.309851</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.133367</td>\n",
       "      <td>-2.019846</td>\n",
       "      <td>-1.024786</td>\n",
       "      <td>0.331097</td>\n",
       "      <td>0.531833</td>\n",
       "      <td>-1.621019</td>\n",
       "      <td>-2.158077</td>\n",
       "      <td>-2.502774</td>\n",
       "      <td>-0.676133</td>\n",
       "      <td>2.089097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-698.721130</td>\n",
       "      <td>47.088486</td>\n",
       "      <td>-11.333614</td>\n",
       "      <td>12.963089</td>\n",
       "      <td>-8.005651</td>\n",
       "      <td>-1.252229</td>\n",
       "      <td>-10.009068</td>\n",
       "      <td>-9.434125</td>\n",
       "      <td>-10.318874</td>\n",
       "      <td>-0.864674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.299306</td>\n",
       "      <td>-0.004270</td>\n",
       "      <td>-1.408216</td>\n",
       "      <td>0.958172</td>\n",
       "      <td>2.574661</td>\n",
       "      <td>1.877764</td>\n",
       "      <td>1.608618</td>\n",
       "      <td>0.222401</td>\n",
       "      <td>4.338524</td>\n",
       "      <td>4.266795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-715.922607</td>\n",
       "      <td>71.976791</td>\n",
       "      <td>4.457525</td>\n",
       "      <td>18.602497</td>\n",
       "      <td>8.404046</td>\n",
       "      <td>3.621954</td>\n",
       "      <td>-1.974365</td>\n",
       "      <td>0.022673</td>\n",
       "      <td>-2.678083</td>\n",
       "      <td>4.232803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505697</td>\n",
       "      <td>0.424780</td>\n",
       "      <td>0.972097</td>\n",
       "      <td>0.210004</td>\n",
       "      <td>0.667769</td>\n",
       "      <td>1.918957</td>\n",
       "      <td>0.174543</td>\n",
       "      <td>-1.768463</td>\n",
       "      <td>-1.512280</td>\n",
       "      <td>-0.253280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>-405.257812</td>\n",
       "      <td>41.294205</td>\n",
       "      <td>-30.586042</td>\n",
       "      <td>-0.538227</td>\n",
       "      <td>-18.484348</td>\n",
       "      <td>-14.656284</td>\n",
       "      <td>-16.151356</td>\n",
       "      <td>-13.920813</td>\n",
       "      <td>-16.820213</td>\n",
       "      <td>3.324283</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.249055</td>\n",
       "      <td>0.077632</td>\n",
       "      <td>-0.483442</td>\n",
       "      <td>-0.436015</td>\n",
       "      <td>0.735576</td>\n",
       "      <td>1.786816</td>\n",
       "      <td>1.513320</td>\n",
       "      <td>3.222856</td>\n",
       "      <td>4.312741</td>\n",
       "      <td>5.172601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>-473.056061</td>\n",
       "      <td>53.553688</td>\n",
       "      <td>-20.607430</td>\n",
       "      <td>10.907098</td>\n",
       "      <td>-1.008979</td>\n",
       "      <td>-5.573545</td>\n",
       "      <td>-19.404833</td>\n",
       "      <td>5.218593</td>\n",
       "      <td>-28.027699</td>\n",
       "      <td>-6.464190</td>\n",
       "      <td>...</td>\n",
       "      <td>1.640660</td>\n",
       "      <td>-2.040031</td>\n",
       "      <td>-0.220178</td>\n",
       "      <td>-0.151539</td>\n",
       "      <td>-3.876288</td>\n",
       "      <td>1.615301</td>\n",
       "      <td>4.084427</td>\n",
       "      <td>9.134243</td>\n",
       "      <td>11.374112</td>\n",
       "      <td>14.116317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>-474.610382</td>\n",
       "      <td>24.998922</td>\n",
       "      <td>-24.003815</td>\n",
       "      <td>2.117282</td>\n",
       "      <td>-15.958261</td>\n",
       "      <td>-8.645466</td>\n",
       "      <td>-19.333958</td>\n",
       "      <td>-6.487021</td>\n",
       "      <td>-26.644005</td>\n",
       "      <td>0.500758</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.764503</td>\n",
       "      <td>2.385815</td>\n",
       "      <td>-0.887787</td>\n",
       "      <td>-4.043890</td>\n",
       "      <td>-1.560124</td>\n",
       "      <td>0.833699</td>\n",
       "      <td>1.932070</td>\n",
       "      <td>-1.613097</td>\n",
       "      <td>1.777461</td>\n",
       "      <td>7.443244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>-463.701447</td>\n",
       "      <td>60.063808</td>\n",
       "      <td>-25.744654</td>\n",
       "      <td>10.314075</td>\n",
       "      <td>4.596226</td>\n",
       "      <td>-9.529220</td>\n",
       "      <td>-17.214312</td>\n",
       "      <td>-7.799369</td>\n",
       "      <td>-18.088699</td>\n",
       "      <td>-0.637278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438399</td>\n",
       "      <td>-0.092735</td>\n",
       "      <td>-1.187605</td>\n",
       "      <td>-1.340231</td>\n",
       "      <td>-0.190074</td>\n",
       "      <td>1.682774</td>\n",
       "      <td>7.134923</td>\n",
       "      <td>9.182275</td>\n",
       "      <td>12.354645</td>\n",
       "      <td>11.913918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>-469.952301</td>\n",
       "      <td>24.855492</td>\n",
       "      <td>-14.537213</td>\n",
       "      <td>2.183493</td>\n",
       "      <td>-22.056345</td>\n",
       "      <td>-4.090179</td>\n",
       "      <td>-12.715465</td>\n",
       "      <td>-5.515845</td>\n",
       "      <td>-12.651355</td>\n",
       "      <td>0.111079</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.175246</td>\n",
       "      <td>1.521526</td>\n",
       "      <td>-1.151882</td>\n",
       "      <td>-1.664821</td>\n",
       "      <td>-0.822573</td>\n",
       "      <td>2.082598</td>\n",
       "      <td>1.597399</td>\n",
       "      <td>1.057190</td>\n",
       "      <td>1.596515</td>\n",
       "      <td>5.777690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2452 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1          2          3          4          5   \\\n",
       "0    -700.398926  58.630211  -3.025852  16.040241   4.248529   3.869935   \n",
       "1    -653.169006  58.028076 -12.581207  11.818786  -7.681562  -0.617142   \n",
       "2    -617.052307  60.103371  -5.984258  13.886285   1.120427   0.511750   \n",
       "3    -698.721130  47.088486 -11.333614  12.963089  -8.005651  -1.252229   \n",
       "4    -715.922607  71.976791   4.457525  18.602497   8.404046   3.621954   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "2447 -405.257812  41.294205 -30.586042  -0.538227 -18.484348 -14.656284   \n",
       "2448 -473.056061  53.553688 -20.607430  10.907098  -1.008979  -5.573545   \n",
       "2449 -474.610382  24.998922 -24.003815   2.117282 -15.958261  -8.645466   \n",
       "2450 -463.701447  60.063808 -25.744654  10.314075   4.596226  -9.529220   \n",
       "2451 -469.952301  24.855492 -14.537213   2.183493 -22.056345  -4.090179   \n",
       "\n",
       "             6          7          8         9   ...        30        31  \\\n",
       "0     -6.381716  -0.188635 -13.735004 -0.319724  ... -1.411359 -2.769772   \n",
       "1     -8.337758  -5.823570  -6.547592  1.458057  ...  0.788761  2.570493   \n",
       "2    -14.841356  -4.016369  -5.575839 -6.309851  ... -1.133367 -2.019846   \n",
       "3    -10.009068  -9.434125 -10.318874 -0.864674  ... -0.299306 -0.004270   \n",
       "4     -1.974365   0.022673  -2.678083  4.232803  ...  0.505697  0.424780   \n",
       "...         ...        ...        ...       ...  ...       ...       ...   \n",
       "2447 -16.151356 -13.920813 -16.820213  3.324283  ... -1.249055  0.077632   \n",
       "2448 -19.404833   5.218593 -28.027699 -6.464190  ...  1.640660 -2.040031   \n",
       "2449 -19.333958  -6.487021 -26.644005  0.500758  ... -1.764503  2.385815   \n",
       "2450 -17.214312  -7.799369 -18.088699 -0.637278  ... -0.438399 -0.092735   \n",
       "2451 -12.715465  -5.515845 -12.651355  0.111079  ... -2.175246  1.521526   \n",
       "\n",
       "            32        33        34        35        36        37         38  \\\n",
       "0    -2.042009 -2.522663 -2.507448 -2.250499 -0.381506 -2.481059  -2.791022   \n",
       "1     2.558634  3.708506  2.790020  2.201920 -1.021456  0.819200  -0.277811   \n",
       "2    -1.024786  0.331097  0.531833 -1.621019 -2.158077 -2.502774  -0.676133   \n",
       "3    -1.408216  0.958172  2.574661  1.877764  1.608618  0.222401   4.338524   \n",
       "4     0.972097  0.210004  0.667769  1.918957  0.174543 -1.768463  -1.512280   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "2447 -0.483442 -0.436015  0.735576  1.786816  1.513320  3.222856   4.312741   \n",
       "2448 -0.220178 -0.151539 -3.876288  1.615301  4.084427  9.134243  11.374112   \n",
       "2449 -0.887787 -4.043890 -1.560124  0.833699  1.932070 -1.613097   1.777461   \n",
       "2450 -1.187605 -1.340231 -0.190074  1.682774  7.134923  9.182275  12.354645   \n",
       "2451 -1.151882 -1.664821 -0.822573  2.082598  1.597399  1.057190   1.596515   \n",
       "\n",
       "             39  \n",
       "0     -2.244865  \n",
       "1      0.207586  \n",
       "2      2.089097  \n",
       "3      4.266795  \n",
       "4     -0.253280  \n",
       "...         ...  \n",
       "2447   5.172601  \n",
       "2448  14.116317  \n",
       "2449   7.443244  \n",
       "2450  11.913918  \n",
       "2451   5.777690  \n",
       "\n",
       "[2452 rows x 40 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1193488b-9532-4871-ba6f-7fe9696d5eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "249808a8-8af8-41b9-aedf-88a9f551d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, 5, padding='same',\n",
    "                input_shape=(40,1)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94475cab-ad1e-47ef-81e9-d147889ce1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 40, 64)            384       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 20488     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 20,872\n",
      "Trainable params: 20,872\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58bb419e-4ff2-4f09-b812-992ed33baf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ea000ab-ccea-4a44-a646-8fe913a68523",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn = np.expand_dims(X_train, axis = 2)\n",
    "x_testcnn = np.expand_dims(X_test, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "215c89e6-3c7c-4d54-91ce-678f74a232a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1716, 40, 1) (736, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_traincnn.shape, x_testcnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b478d6a-1276-4ca3-a25b-73868e1a033a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5c1fadd-5b6f-47c1-a7db-60886ac4b5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1716,) (736,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12d35d4c-4bcb-45c1-992a-5c0d56ddf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2dd318fb-9523-486c-8aaf-96687053d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                  optimizer = 'rmsprop',\n",
    "                  metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9acb56fc-6ea9-437a-9333-1872c088fd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 3, ..., 6, 7, 4])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e221702-7f38-40d1-9a59-51812decff38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 [==============================] - 4s 8ms/step - loss: 10.9426 - accuracy: 0.1527 - val_loss: 3.2359 - val_accuracy: 0.2500\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.3425 - accuracy: 0.1900 - val_loss: 2.3305 - val_accuracy: 0.3533\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.8465 - accuracy: 0.2290 - val_loss: 3.1259 - val_accuracy: 0.3302\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 5.0888 - accuracy: 0.2587 - val_loss: 3.9147 - val_accuracy: 0.2459\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.1295 - accuracy: 0.2920 - val_loss: 3.5003 - val_accuracy: 0.3709\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 3.3796 - accuracy: 0.3397 - val_loss: 4.2411 - val_accuracy: 0.1916\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 3.1181 - accuracy: 0.3531 - val_loss: 2.5230 - val_accuracy: 0.3614\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 2.5923 - accuracy: 0.3735 - val_loss: 1.7590 - val_accuracy: 0.4851\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 2.1918 - accuracy: 0.4336 - val_loss: 2.8646 - val_accuracy: 0.2989\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1.9102 - accuracy: 0.4487 - val_loss: 1.8496 - val_accuracy: 0.4103\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1.8140 - accuracy: 0.4458 - val_loss: 1.5409 - val_accuracy: 0.5054\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1.5775 - accuracy: 0.4883 - val_loss: 1.9348 - val_accuracy: 0.4443\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1.3957 - accuracy: 0.5152 - val_loss: 1.5428 - val_accuracy: 0.4823\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1.3786 - accuracy: 0.5280 - val_loss: 1.4693 - val_accuracy: 0.4837\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 1.2875 - accuracy: 0.5437 - val_loss: 1.4033 - val_accuracy: 0.4769\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1.1867 - accuracy: 0.5624 - val_loss: 1.3184 - val_accuracy: 0.5312\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1.1771 - accuracy: 0.5688 - val_loss: 1.2240 - val_accuracy: 0.5747\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 1.1092 - accuracy: 0.5880 - val_loss: 1.2730 - val_accuracy: 0.5476\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1.0796 - accuracy: 0.5967 - val_loss: 1.2135 - val_accuracy: 0.5666\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1.0210 - accuracy: 0.6230 - val_loss: 1.1500 - val_accuracy: 0.6114\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1.0041 - accuracy: 0.6358 - val_loss: 1.1475 - val_accuracy: 0.5734\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1.0094 - accuracy: 0.6364 - val_loss: 1.2174 - val_accuracy: 0.5516\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.9493 - accuracy: 0.6451 - val_loss: 1.1663 - val_accuracy: 0.5829\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.9725 - accuracy: 0.6364 - val_loss: 1.1771 - val_accuracy: 0.5734\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.9281 - accuracy: 0.6737 - val_loss: 1.1646 - val_accuracy: 0.5829\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.9232 - accuracy: 0.6661 - val_loss: 1.1480 - val_accuracy: 0.5978\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.9031 - accuracy: 0.6597 - val_loss: 1.1337 - val_accuracy: 0.5924\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.8992 - accuracy: 0.6597 - val_loss: 1.1568 - val_accuracy: 0.6141\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.9073 - accuracy: 0.6836 - val_loss: 1.1493 - val_accuracy: 0.5788\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.8634 - accuracy: 0.6707 - val_loss: 1.1465 - val_accuracy: 0.6155\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8876 - accuracy: 0.6678 - val_loss: 1.1507 - val_accuracy: 0.5992\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.8425 - accuracy: 0.6871 - val_loss: 1.1211 - val_accuracy: 0.5992\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8555 - accuracy: 0.6935 - val_loss: 1.1201 - val_accuracy: 0.6141\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.8135 - accuracy: 0.7010 - val_loss: 1.1562 - val_accuracy: 0.5897\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8203 - accuracy: 0.6888 - val_loss: 1.1385 - val_accuracy: 0.5829\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.8069 - accuracy: 0.7051 - val_loss: 1.2152 - val_accuracy: 0.5815\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.7843 - accuracy: 0.7145 - val_loss: 1.0977 - val_accuracy: 0.6060\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.7693 - accuracy: 0.7098 - val_loss: 1.1474 - val_accuracy: 0.5992\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.7910 - accuracy: 0.7045 - val_loss: 1.1870 - val_accuracy: 0.6005\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.7837 - accuracy: 0.7168 - val_loss: 1.2475 - val_accuracy: 0.5625\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.7716 - accuracy: 0.7127 - val_loss: 1.1424 - val_accuracy: 0.5883\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.7796 - accuracy: 0.7220 - val_loss: 1.0569 - val_accuracy: 0.6209\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.7333 - accuracy: 0.7337 - val_loss: 1.1082 - val_accuracy: 0.6155\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.7547 - accuracy: 0.7174 - val_loss: 1.0848 - val_accuracy: 0.6291\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.7448 - accuracy: 0.7162 - val_loss: 1.1541 - val_accuracy: 0.6033\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.7405 - accuracy: 0.7168 - val_loss: 1.0450 - val_accuracy: 0.6359\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.7268 - accuracy: 0.7337 - val_loss: 1.0491 - val_accuracy: 0.6332\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.7465 - accuracy: 0.7337 - val_loss: 1.1133 - val_accuracy: 0.6277\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.7074 - accuracy: 0.7284 - val_loss: 1.1721 - val_accuracy: 0.5910\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6993 - accuracy: 0.7383 - val_loss: 1.0295 - val_accuracy: 0.6481\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.7045 - accuracy: 0.7366 - val_loss: 1.1197 - val_accuracy: 0.6359\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.7159 - accuracy: 0.7331 - val_loss: 1.1826 - val_accuracy: 0.6087\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.7477 - val_loss: 1.1089 - val_accuracy: 0.6223\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.7541 - val_loss: 1.0735 - val_accuracy: 0.6386\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6984 - accuracy: 0.7523 - val_loss: 1.2604 - val_accuracy: 0.5870\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.7593 - val_loss: 1.0648 - val_accuracy: 0.6318\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.7576 - val_loss: 1.1350 - val_accuracy: 0.6033\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.7424 - val_loss: 1.0571 - val_accuracy: 0.6535\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.7727 - val_loss: 1.0657 - val_accuracy: 0.6427\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.7442 - val_loss: 1.0782 - val_accuracy: 0.6481\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6493 - accuracy: 0.7570 - val_loss: 1.1022 - val_accuracy: 0.6291\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6651 - accuracy: 0.7541 - val_loss: 1.1535 - val_accuracy: 0.6318\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.7430 - val_loss: 1.0964 - val_accuracy: 0.6576\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.7617 - val_loss: 1.1635 - val_accuracy: 0.6223\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.7512 - val_loss: 1.0851 - val_accuracy: 0.6508\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.7564 - val_loss: 1.0552 - val_accuracy: 0.6549\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.7692 - val_loss: 1.2104 - val_accuracy: 0.6046\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.7500 - val_loss: 1.1201 - val_accuracy: 0.6236\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7675 - val_loss: 1.1239 - val_accuracy: 0.6182\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.6428 - accuracy: 0.7657 - val_loss: 1.0828 - val_accuracy: 0.6508\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.7716 - val_loss: 1.0610 - val_accuracy: 0.6535\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.7663 - val_loss: 1.0590 - val_accuracy: 0.6576\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.7686 - val_loss: 1.0707 - val_accuracy: 0.6454\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.7716 - val_loss: 1.1444 - val_accuracy: 0.6427\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6243 - accuracy: 0.7640 - val_loss: 1.0726 - val_accuracy: 0.6481\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5803 - accuracy: 0.7815 - val_loss: 1.1306 - val_accuracy: 0.6359\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6031 - accuracy: 0.7698 - val_loss: 1.0517 - val_accuracy: 0.6698\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.7605 - val_loss: 1.1307 - val_accuracy: 0.6399\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.7838 - val_loss: 1.1083 - val_accuracy: 0.6481\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.7756 - val_loss: 1.1595 - val_accuracy: 0.6291\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.5809 - accuracy: 0.7844 - val_loss: 1.0651 - val_accuracy: 0.6617\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.7826 - val_loss: 1.0548 - val_accuracy: 0.6671\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.7949 - val_loss: 1.1119 - val_accuracy: 0.6372\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5805 - accuracy: 0.7873 - val_loss: 1.0877 - val_accuracy: 0.6630\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.7867 - val_loss: 1.1862 - val_accuracy: 0.6114\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5889 - accuracy: 0.7896 - val_loss: 1.0965 - val_accuracy: 0.6481\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7925 - val_loss: 1.0381 - val_accuracy: 0.6671\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7803 - val_loss: 1.2044 - val_accuracy: 0.6250\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.7855 - val_loss: 1.2370 - val_accuracy: 0.6264\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5600 - accuracy: 0.7937 - val_loss: 1.1657 - val_accuracy: 0.6440\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.7908 - val_loss: 1.0634 - val_accuracy: 0.6644\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.7885 - val_loss: 1.1073 - val_accuracy: 0.6508\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.8001 - val_loss: 1.1854 - val_accuracy: 0.6277\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.8100 - val_loss: 1.1137 - val_accuracy: 0.6549\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7920 - val_loss: 1.0970 - val_accuracy: 0.6590\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.8129 - val_loss: 1.1275 - val_accuracy: 0.6495\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.8065 - val_loss: 1.2493 - val_accuracy: 0.6196\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.8106 - val_loss: 1.1557 - val_accuracy: 0.6467\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.8065 - val_loss: 1.2550 - val_accuracy: 0.6060\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.8135 - val_loss: 1.0825 - val_accuracy: 0.6576\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_traincnn, y_train,\n",
    "                    batch_size = 64,\n",
    "                    epochs = 100,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e31e057f-3ae1-4840-af67-a0c5d4fb23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, sample_rate = librosa.load(os.path.join('test/surprised.wav'), res_type='kaiser_fast')\n",
    "\n",
    "mfccs = np.mean(librosa.feature.mfcc(y = X, sr = sample_rate, n_mfcc = 40).T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4d705d9b-f453-4575-8464-effd241a9bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.64376404e+02,  6.04857864e+01, -4.18858099e+00,  1.69400635e+01,\n",
       "       -4.00226861e-01,  2.59444976e+00, -7.45956182e+00, -4.03830099e+00,\n",
       "       -1.40770035e+01,  2.06803262e-01, -3.32057571e+00, -1.55312514e+00,\n",
       "       -3.92186618e+00, -3.76724315e+00, -3.78725290e+00,  2.12958837e+00,\n",
       "       -7.63181829e+00, -2.46205378e+00, -1.55082119e+00, -6.30556107e-01,\n",
       "       -8.21463680e+00, -2.07641864e+00, -3.25763845e+00, -4.19562912e+00,\n",
       "       -3.53725982e+00, -2.67386293e+00, -4.61865854e+00, -1.77279270e+00,\n",
       "       -1.58636880e+00, -1.73208976e+00, -2.31740212e+00, -2.67540956e+00,\n",
       "       -2.37380433e+00, -4.09476566e+00, -3.43976617e+00, -3.96298289e+00,\n",
       "       -4.75864887e-01, -2.83636737e+00, -2.15631056e+00, -2.89204311e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "420d7b93-1751-42b8-a982-dd518de6c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = pd.DataFrame([mfccs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e88c74fe-b436-4867-bfc5-20a76402f1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-664.376404</td>\n",
       "      <td>60.485786</td>\n",
       "      <td>-4.188581</td>\n",
       "      <td>16.940063</td>\n",
       "      <td>-0.400227</td>\n",
       "      <td>2.59445</td>\n",
       "      <td>-7.459562</td>\n",
       "      <td>-4.038301</td>\n",
       "      <td>-14.077003</td>\n",
       "      <td>0.206803</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.317402</td>\n",
       "      <td>-2.67541</td>\n",
       "      <td>-2.373804</td>\n",
       "      <td>-4.094766</td>\n",
       "      <td>-3.439766</td>\n",
       "      <td>-3.962983</td>\n",
       "      <td>-0.475865</td>\n",
       "      <td>-2.836367</td>\n",
       "      <td>-2.156311</td>\n",
       "      <td>-2.892043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1         2          3         4        5         6   \\\n",
       "0 -664.376404  60.485786 -4.188581  16.940063 -0.400227  2.59445 -7.459562   \n",
       "\n",
       "         7          8         9   ...        30       31        32        33  \\\n",
       "0 -4.038301 -14.077003  0.206803  ... -2.317402 -2.67541 -2.373804 -4.094766   \n",
       "\n",
       "         34        35        36        37        38        39  \n",
       "0 -3.439766 -3.962983 -0.475865 -2.836367 -2.156311 -2.892043  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5c0bd6db-44dc-457e-8bf8-0fd8b5a00b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.expand_dims(mfccs, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0cf72efa-162f-49ba-b319-f49e0c4771d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40, 1)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fe1e2beb-4f1e-4369-a4f5-ead565dc6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = {0: 'neutral', 1: 'calm', 2: 'happy', 3: 'sad', 4: 'angry', 5: 'fearful', 6: 'disgust', 7: 'surprised'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "99fc838a-f133-4e29-a3cb-dfa6f1b0de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0529be41-e4c7-40cb-bc0e-493e16aa60aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'calm'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion[pred.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276a7c4-13b2-4d8e-89c6-cc0378935ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
