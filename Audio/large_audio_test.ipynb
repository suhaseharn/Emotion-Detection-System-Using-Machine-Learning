{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "97cc2d9c-b6d3-4db0-aba8-b806619169eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyaudio\n",
    "import wave\n",
    "import librosa\n",
    "from scipy.io.wavfile import write\n",
    "from keras.models import model_from_json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "22092727-78ca-41d6-8a9c-d716028ceff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('models/40/final_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights('models/40/final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "77fa921a-981e-421f-95c8-30488e76206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for audio recording\n",
    "format = pyaudio.paInt16\n",
    "channels = 1\n",
    "filename = \"test/happy.wav\"\n",
    "duration=5\n",
    "sample_rate=44100\n",
    "chunk_size=1024\n",
    "duration=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "26da9231-f148-41f3-ba80-51eb6d61daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to record audio\n",
    "def record_audio():\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=format, channels=channels,\n",
    "                        rate=sample_rate, input=True,\n",
    "                        frames_per_buffer=chunk_size)\n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "\n",
    "    # Calculate total number of chunks\n",
    "    total_chunks = int(sample_rate / chunk_size * duration)\n",
    "    chunks_per_marker = total_chunks // 10  # Number of chunks for each '#' character\n",
    "\n",
    "    for i in range(total_chunks):\n",
    "        data = stream.read(chunk_size)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"\\nFinished recording.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    wavefile = wave.open(filename, 'wb')\n",
    "    wavefile.setnchannels(channels)\n",
    "    wavefile.setsampwidth(audio.get_sample_size(format))\n",
    "    wavefile.setframerate(sample_rate)\n",
    "    wavefile.writeframes(b''.join(frames))\n",
    "    wavefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f87c66cb-ca39-4e17-ab5e-1836a8c244a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for audio feature extraction\n",
    "mfcc_sample_rate = 22050\n",
    "n_mfcc = 40\n",
    "axis_mfcc = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d26ecfca-db16-434b-9306-5705b87a05ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_audio(segment_length,sr,y):\n",
    "\n",
    "    # Calculate the length of each segment in samples\n",
    "    segment_samples = int(segment_length * sr)\n",
    "\n",
    "    # Calculate the total number of segments\n",
    "    num_segments = len(y) // segment_samples\n",
    "\n",
    "    segments = []\n",
    "\n",
    "    # Extract segments\n",
    "    for i in range(num_segments):\n",
    "        start_sample = i * segment_samples\n",
    "        end_sample = (i + 1) * segment_samples\n",
    "        segment = y[start_sample:end_sample]\n",
    "        segments.append(segment)\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d6f2f499-9bba-4ca7-b0a4-5612d1723e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(filename, sample_rate=22050, n_mfcc=40, offset_s=0.5):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(filename, sr=sample_rate, mono=True, offset=offset_s)\n",
    "    y_trimmed, _ = librosa.effects.trim(y)\n",
    "\n",
    "    return segment_audio(segment_length=5,sr=sr,y=y_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "21f8df45-03f7-456b-ae6f-6c2eaf086135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#record_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b8fc38cb-f4ff-483a-b1d5-28c8fa418789",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = preprocess_audio(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e1bc2167-2d33-4062-86d0-e98ee87b78c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-3.6446705e-05, -5.0137372e-05, -2.6092066e-05, ...,\n",
       "         1.8418679e-02,  1.7382352e-02,  1.5644714e-02], dtype=float32),\n",
       " array([ 0.01273728,  0.00885533,  0.00448044, ..., -0.01707608,\n",
       "        -0.01268003, -0.01094848], dtype=float32),\n",
       " array([-0.01006793, -0.00881656, -0.00694277, ...,  0.0110437 ,\n",
       "         0.01377037,  0.01493229], dtype=float32),\n",
       " array([0.01519687, 0.01360911, 0.01059486, ..., 0.01880057, 0.01818263,\n",
       "        0.01840654], dtype=float32),\n",
       " array([ 0.01856009,  0.01891422,  0.01993833, ..., -0.03093199,\n",
       "        -0.0287811 , -0.02659699], dtype=float32)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b4f02a8-b1c6-4783-a032-6c5b4de9a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "ravdess = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for i in segments:\n",
    "    mfccs = librosa.feature.mfcc(y=i, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    #Add MFCCs feature results to list\n",
    "    ravdess.loc[bookmark] = [mfccs_mean]\n",
    "    bookmark=bookmark+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7dc85f37-d3f1-4ecf-87f7-50749e33eea3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-319.9953, 169.50264, -6.675172, 8.762605, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-367.64487, 156.09085, -23.756754, 36.41025, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-373.31763, 148.85207, -14.554767, 35.97845, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-370.79465, 138.36104, -15.291364, 33.030426,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-380.7688, 150.3276, -25.56467, 40.309135, 2....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature\n",
       "0  [-319.9953, 169.50264, -6.675172, 8.762605, -1...\n",
       "1  [-367.64487, 156.09085, -23.756754, 36.41025, ...\n",
       "2  [-373.31763, 148.85207, -14.554767, 35.97845, ...\n",
       "3  [-370.79465, 138.36104, -15.291364, 33.030426,...\n",
       "4  [-380.7688, 150.3276, -25.56467, 40.309135, 2...."
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ravdess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b15d045d-2120-42c3-bbaf-e613077058ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn array into dataframe\n",
    "ravdess_final = pd.DataFrame(ravdess['feature'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f8e54485-82dd-43b7-bd96-0c24da9e08b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 40)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analyze new dataframe shape\n",
    "ravdess_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e0f8a5da-1a61-4f6a-81b9-1a7f3fbc9d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('meta/scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f70106bb-4a24-4378-a0e7-4c75f9ee27df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cnn = scaler.transform(ravdess_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c9158963-1574-4ae5-b4f2-4ac93492e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.expand_dims(x_cnn, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "771a82a4-13be-411b-a9eb-b3e723964025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 40, 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8bb9227a-c791-4fcf-9e93-8f5c48d675d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model.predict(x),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "db4a634e-f24d-453a-8a57-99917247b0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8d7a6267-aef0-4fb2-af29-161588b36458",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {0:'neutral', 1:'calm', 2:'happy', 3:'sad', 4:'angry', 5:'fear', 6:'disgust', 7:'surprised'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d8bfe2d5-3730-46c4-a7bb-a858aaf34529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fear'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions[max(predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b979b3-c27d-4426-9267-8e9a52f3bed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
